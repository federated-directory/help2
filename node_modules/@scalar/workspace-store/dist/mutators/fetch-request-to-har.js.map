{
  "version": 3,
  "sources": ["../../src/mutators/fetch-request-to-har.ts"],
  "sourcesContent": ["import type { HarRequest } from '@scalar/snippetz'\n\ntype FetchRequestToHarProps = {\n  /** The Fetch API Request object to convert */\n  request: Request\n  /**\n   * Whether to include the request body in the HAR postData.\n   * Note: Reading the body consumes it, so the request will be cloned automatically.\n   * @default true\n   */\n  includeBody?: boolean\n  /**\n   * HTTP version string to use (since Fetch API does not expose this)\n   * @default 'HTTP/1.1'\n   */\n  httpVersion?: string\n  /**\n   * The maximum size of the request body to include in the HAR postData.\n   * @default 1MB\n   */\n  bodySizeLimit?: number\n}\n\n/**\n * Converts a Fetch API Request object to HAR (HTTP Archive) Request format.\n *\n * This function transforms a standard JavaScript Fetch API Request into the\n * HAR format, which is useful for:\n * - Recording HTTP requests for replay or analysis\n * - Creating request fixtures from real API calls\n * - Debugging and monitoring HTTP traffic\n * - Storing request history in a standard format\n * - Generating API documentation from real requests\n *\n * The conversion handles:\n * - Request method and URL\n * - Headers extraction (excluding sensitive headers if needed)\n * - Query parameters extraction from URL\n * - Cookie extraction from headers\n * - Request body reading (with automatic cloning to preserve the original)\n * - Content-Type detection and MIME type extraction\n * - Size calculations for headers and body\n * - Form data bodies are converted to params array\n * - Other body types are read as text\n *\n * Note: The Fetch API does not expose the HTTP version, so it defaults to HTTP/1.1\n * unless specified otherwise.\n *\n * @see https://w3c.github.io/web-performance/specs/HAR/Overview.html\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Request\n *\n * @example\n * const request = new Request('https://api.example.com/users', {\n *   method: 'POST',\n *   headers: { 'Content-Type': 'application/json' },\n *   body: JSON.stringify({ name: 'John' })\n * })\n * const harRequest = await fetchRequestToHar({ request })\n * console.log(harRequest.method) // 'POST'\n * console.log(harRequest.postData?.text) // '{\"name\":\"John\"}'\n */\nexport const fetchRequestToHar = async ({\n  request,\n  includeBody = true,\n  httpVersion = 'HTTP/1.1',\n  // Default to 1MB\n  bodySizeLimit = 1048576,\n}: FetchRequestToHarProps): Promise<HarRequest> => {\n  // Extract query string from URL\n  const url = new URL(request.url)\n\n  // Extract the query strings from the URL\n  const queryString = Array.from(url.searchParams.entries()).map(([name, value]) => ({ name, value }))\n\n  // Extract the headers from the request\n  const { headers, headersSize, cookies } = processRequestHeaders(request)\n\n  // Extract the MIME type from the request headers\n  const mimeType = request.headers.get('content-type')?.split(';')[0]?.trim() ?? 'text/plain'\n\n  // Read the request body if requested\n  const bodyDetails = await (async () => {\n    if (includeBody && request.body) {\n      const details = await processRequestBody(request.clone())\n      if (details.size <= bodySizeLimit) {\n        return details\n      }\n    }\n    return { text: '', size: -1 }\n  })()\n\n  // Create the HAR request object\n  const harRequest: HarRequest = {\n    method: request.method,\n    url: request.url,\n    httpVersion,\n    headers,\n    cookies,\n    queryString,\n    headersSize,\n    bodySize: bodyDetails.size,\n    postData:\n      'params' in bodyDetails\n        ? {\n            mimeType,\n            params: bodyDetails.params,\n          }\n        : {\n            mimeType,\n            text: bodyDetails.text,\n          },\n  }\n\n  return harRequest\n}\n\nconst processRequestBody = async (request: Request) => {\n  const formData = await tryGetRequestFormData(request.clone())\n  if (formData) {\n    return Array.from(formData.entries()).reduce<{ params: { name: string; value: string }[]; size: number }>(\n      (acc, [name, value]) => {\n        if (value instanceof File) {\n          const fileName = `@${value.name}`\n          acc.params.push({ name, value: fileName })\n          acc.size += fileName.length\n          return acc\n        }\n\n        acc.params.push({ name, value })\n        acc.size += value.length\n        return acc\n      },\n      { params: [], size: 0 },\n    )\n  }\n  // Skip binary bodies\n  if (request.headers.get('content-type')?.includes('application/octet-stream')) {\n    return { text: '', size: -1 }\n  }\n\n  // Read the request body as text\n  const arrayBuffer = await request.arrayBuffer()\n  const size = arrayBuffer.byteLength\n  return { size, text: new TextDecoder().decode(arrayBuffer) }\n}\n\nasync function tryGetRequestFormData(request: Request): Promise<FormData | null> {\n  if (typeof request.formData !== 'function') {\n    return null\n  }\n\n  if (request.bodyUsed) {\n    return null\n  }\n\n  const contentType = request.headers.get('content-type') ?? ''\n  if (!contentType.includes('multipart/form-data') && !contentType.includes('application/x-www-form-urlencoded')) {\n    return null\n  }\n\n  try {\n    return await request.formData()\n  } catch {\n    return null\n  }\n}\n\nconst processRequestHeaders = (request: Request) => {\n  return Array.from(request.headers.entries()).reduce<{\n    headers: { name: string; value: string }[]\n    headersSize: number\n    cookies: { name: string; value: string }[]\n  }>(\n    (acc, [name, value]) => {\n      if (name.toLowerCase() === 'cookie') {\n        const parsedCookies = parseCookieHeader(value)\n        acc.cookies.push(...parsedCookies.cookies)\n      } else {\n        acc.headers.push({ name, value })\n        acc.headersSize += name.length + 2 + value.length + 2\n      }\n      return acc\n    },\n    { headers: [], headersSize: 0, cookies: [] },\n  )\n}\n\n/**\n * Parses a Cookie header value into an array of cookie objects.\n * Cookie format: name1=value1; name2=value2\n */\nconst parseCookieHeader = (cookieValue: string) => {\n  return cookieValue.split(';').reduce<{ cookies: { name: string; value: string }[]; size: number }>(\n    (acc, part) => {\n      const trimmedPart = part.trim()\n      const equalIndex = trimmedPart.indexOf('=')\n\n      if (equalIndex === -1) {\n        return acc\n      }\n\n      const name = trimmedPart.substring(0, equalIndex).trim()\n      const value = trimmedPart.substring(equalIndex + 1).trim()\n\n      acc.cookies.push({ name, value })\n      acc.size += name.length + 2 + value.length + 2\n      return acc\n    },\n    { cookies: [], size: 0 },\n  )\n}\n"],
  "mappings": "AA6DO,MAAM,oBAAoB,OAAO;AAAA,EACtC;AAAA,EACA,cAAc;AAAA,EACd,cAAc;AAAA;AAAA,EAEd,gBAAgB;AAClB,MAAmD;AAEjD,QAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAG/B,QAAM,cAAc,MAAM,KAAK,IAAI,aAAa,QAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,MAAM,KAAK,OAAO,EAAE,MAAM,MAAM,EAAE;AAGnG,QAAM,EAAE,SAAS,aAAa,QAAQ,IAAI,sBAAsB,OAAO;AAGvE,QAAM,WAAW,QAAQ,QAAQ,IAAI,cAAc,GAAG,MAAM,GAAG,EAAE,CAAC,GAAG,KAAK,KAAK;AAG/E,QAAM,cAAc,OAAO,YAAY;AACrC,QAAI,eAAe,QAAQ,MAAM;AAC/B,YAAM,UAAU,MAAM,mBAAmB,QAAQ,MAAM,CAAC;AACxD,UAAI,QAAQ,QAAQ,eAAe;AACjC,eAAO;AAAA,MACT;AAAA,IACF;AACA,WAAO,EAAE,MAAM,IAAI,MAAM,GAAG;AAAA,EAC9B,GAAG;AAGH,QAAM,aAAyB;AAAA,IAC7B,QAAQ,QAAQ;AAAA,IAChB,KAAK,QAAQ;AAAA,IACb;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,UAAU,YAAY;AAAA,IACtB,UACE,YAAY,cACR;AAAA,MACE;AAAA,MACA,QAAQ,YAAY;AAAA,IACtB,IACA;AAAA,MACE;AAAA,MACA,MAAM,YAAY;AAAA,IACpB;AAAA,EACR;AAEA,SAAO;AACT;AAEA,MAAM,qBAAqB,OAAO,YAAqB;AACrD,QAAM,WAAW,MAAM,sBAAsB,QAAQ,MAAM,CAAC;AAC5D,MAAI,UAAU;AACZ,WAAO,MAAM,KAAK,SAAS,QAAQ,CAAC,EAAE;AAAA,MACpC,CAAC,KAAK,CAAC,MAAM,KAAK,MAAM;AACtB,YAAI,iBAAiB,MAAM;AACzB,gBAAM,WAAW,IAAI,MAAM,IAAI;AAC/B,cAAI,OAAO,KAAK,EAAE,MAAM,OAAO,SAAS,CAAC;AACzC,cAAI,QAAQ,SAAS;AACrB,iBAAO;AAAA,QACT;AAEA,YAAI,OAAO,KAAK,EAAE,MAAM,MAAM,CAAC;AAC/B,YAAI,QAAQ,MAAM;AAClB,eAAO;AAAA,MACT;AAAA,MACA,EAAE,QAAQ,CAAC,GAAG,MAAM,EAAE;AAAA,IACxB;AAAA,EACF;AAEA,MAAI,QAAQ,QAAQ,IAAI,cAAc,GAAG,SAAS,0BAA0B,GAAG;AAC7E,WAAO,EAAE,MAAM,IAAI,MAAM,GAAG;AAAA,EAC9B;AAGA,QAAM,cAAc,MAAM,QAAQ,YAAY;AAC9C,QAAM,OAAO,YAAY;AACzB,SAAO,EAAE,MAAM,MAAM,IAAI,YAAY,EAAE,OAAO,WAAW,EAAE;AAC7D;AAEA,eAAe,sBAAsB,SAA4C;AAC/E,MAAI,OAAO,QAAQ,aAAa,YAAY;AAC1C,WAAO;AAAA,EACT;AAEA,MAAI,QAAQ,UAAU;AACpB,WAAO;AAAA,EACT;AAEA,QAAM,cAAc,QAAQ,QAAQ,IAAI,cAAc,KAAK;AAC3D,MAAI,CAAC,YAAY,SAAS,qBAAqB,KAAK,CAAC,YAAY,SAAS,mCAAmC,GAAG;AAC9G,WAAO;AAAA,EACT;AAEA,MAAI;AACF,WAAO,MAAM,QAAQ,SAAS;AAAA,EAChC,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAEA,MAAM,wBAAwB,CAAC,YAAqB;AAClD,SAAO,MAAM,KAAK,QAAQ,QAAQ,QAAQ,CAAC,EAAE;AAAA,IAK3C,CAAC,KAAK,CAAC,MAAM,KAAK,MAAM;AACtB,UAAI,KAAK,YAAY,MAAM,UAAU;AACnC,cAAM,gBAAgB,kBAAkB,KAAK;AAC7C,YAAI,QAAQ,KAAK,GAAG,cAAc,OAAO;AAAA,MAC3C,OAAO;AACL,YAAI,QAAQ,KAAK,EAAE,MAAM,MAAM,CAAC;AAChC,YAAI,eAAe,KAAK,SAAS,IAAI,MAAM,SAAS;AAAA,MACtD;AACA,aAAO;AAAA,IACT;AAAA,IACA,EAAE,SAAS,CAAC,GAAG,aAAa,GAAG,SAAS,CAAC,EAAE;AAAA,EAC7C;AACF;AAMA,MAAM,oBAAoB,CAAC,gBAAwB;AACjD,SAAO,YAAY,MAAM,GAAG,EAAE;AAAA,IAC5B,CAAC,KAAK,SAAS;AACb,YAAM,cAAc,KAAK,KAAK;AAC9B,YAAM,aAAa,YAAY,QAAQ,GAAG;AAE1C,UAAI,eAAe,IAAI;AACrB,eAAO;AAAA,MACT;AAEA,YAAM,OAAO,YAAY,UAAU,GAAG,UAAU,EAAE,KAAK;AACvD,YAAM,QAAQ,YAAY,UAAU,aAAa,CAAC,EAAE,KAAK;AAEzD,UAAI,QAAQ,KAAK,EAAE,MAAM,MAAM,CAAC;AAChC,UAAI,QAAQ,KAAK,SAAS,IAAI,MAAM,SAAS;AAC7C,aAAO;AAAA,IACT;AAAA,IACA,EAAE,SAAS,CAAC,GAAG,MAAM,EAAE;AAAA,EACzB;AACF;",
  "names": []
}
